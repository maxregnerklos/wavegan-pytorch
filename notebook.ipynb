{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "WaveGan.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/mostafaelaraby/wavegan-pytorch/blob/master/notebook.ipynb)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GYMymOZmXP05"
      },
      "source": [
        "## Cloning Repository and Setting Up Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!git clone https://github.com/mostafaelaraby/wavegan-pytorch.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "os.chdir('wavegan-pytorch')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip3 install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MyaocfY_XkCx"
      },
      "source": [
        "## Downloading Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "WXnrT31T3T4o"
      },
      "source": [
        "### Speech Commands Zero through Nine (SC09)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!wget http://deepyeti.ucsd.edu/cdonahue/wavegan/data/sc09.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!tar -xvf sc09.tar.gz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tfdKEfBP3bnz"
      },
      "source": [
        "### Drum Sound Effects"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!wget http://deepyeti.ucsd.edu/cdonahue/wavegan/data/drums.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!tar -xvf drums.tar.gz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RgnM-ulA3fx3"
      },
      "source": [
        "### Bach Piano Performances"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!wget http://deepyeti.ucsd.edu/cdonahue/wavegan/data/mancini_piano.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!tar -xvf mancini_piano.tar.gz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SnS4lQeq62gS"
      },
      "source": [
        "### Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import random\n",
        "import numpy as np\n",
        "import logging\n",
        "import os\n",
        "\n",
        "#############################\n",
        "# DataSet Path\n",
        "#############################s\n",
        "target_signals_dir = 'piano'\n",
        "#############################\n",
        "# Model Params\n",
        "#############################\n",
        "model_prefix = 'test' # name of the model to be saved\n",
        "n_iterations = 100000\n",
        "lr_g = 1e-4\n",
        "lr_d = 3e-4 # you can use with discriminator having a larger learning rate than generator instead of using n_critic updates ttur https://arxiv.org/abs/1706.08500\n",
        "beta1 = 0.5\n",
        "beta2 = 0.9\n",
        "use_batchnorm=False\n",
        "validate=True\n",
        "decay_lr = False # used to linearly deay learning rate untill reaching 0 at iteration 100,000\n",
        "generator_batch_size_factor = 1 # in some cases we might try to update the generator with double batch size used in the discriminator https://arxiv.org/abs/1706.08500\n",
        "n_critic = 1 # update generator every n_critic steps if lr_g = lr_d the n_critic's default value is 5 \n",
        "# gradient penalty regularization factor.\n",
        "p_coeff = 10\n",
        "batch_size = 10\n",
        "noise_latent_dim = 100  # size of the sampling noise\n",
        "model_capacity_size = 32    # model capacity during training can be reduced to 32 for larger window length of 2 seconds and 4 seconds\n",
        "# rate of storing validation and costs params\n",
        "store_cost_every = 300\n",
        "progress_bar_step_iter_size = 400\n",
        "#############################\n",
        "# Backup Params\n",
        "#############################\n",
        "take_backup = True\n",
        "backup_every_n_iters = 1000\n",
        "save_samples_every = 1000\n",
        "output_dir = 'output'\n",
        "if not(os.path.isdir(output_dir)):\n",
        "    os.makedirs(output_dir)\n",
        "#############################\n",
        "# Audio Reading Params\n",
        "#############################\n",
        "window_length = 65536 #[16384, 32768, 65536] in case of a longer window change model_capacity_size to 32\n",
        "sampling_rate = 16000\n",
        "normalize_audio = True \n",
        "num_channels = 1\n",
        "\n",
        "#############################\n",
        "# Logger init\n",
        "#############################\n",
        "LOGGER = logging.getLogger('wavegan')\n",
        "LOGGER.setLevel(logging.DEBUG)\n",
        "#############################\n",
        "# Torch Init and seed setting\n",
        "#############################\n",
        "cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda:0\" if (torch.cuda.is_available()) else \"cpu\")\n",
        "# update the seed\n",
        "manual_seed = 2019 \n",
        "random.seed(manual_seed)\n",
        "torch.manual_seed(manual_seed)\n",
        "np.random.seed(manual_seed)\n",
        "if cuda:\n",
        "    torch.cuda.manual_seed(manual_seed)\n",
        "    torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "NUo6Kmg3ZPwy"
      },
      "source": [
        "## Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python3 train.py"
      ]
    }
  ]
}
